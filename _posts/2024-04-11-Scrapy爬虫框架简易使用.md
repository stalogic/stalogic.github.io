---
layout:     post
title:      Scrapy爬虫框架简易使用
subtitle:    "\"人生苦短我用Python\""
date:       2024-04-11
author:     Eason
header-img: img/post-bg-swanlake.jpg
catalog: true
tags:
    - Scrapy
    - Python
    - 爬虫
---



## 前言

最近想用二游的文本来微调大模型，看看能玩出什么有意思的东西。首先得爬取游戏的文本信息，Scrapy是Python爬虫框架，通过阅读文档和博客，很轻松掌握的Scrapy的简单使用，完成爬取数据的目标。

---

### 安装&环境配置

scrapy依赖python环境，可以通过conda创建虚拟环境
```bash
conda create -n venv python=3.10 scrapy
```
顺利安装完成的话，会看见下面的提示

```
# To activate this environment, use
#
#     $ conda activate venv
#
# To deactivate an active environment, use
#
#     $ conda deactivate
```
通过`conda activate venv`命令就可以进入虚拟环境，`conda deactivate`命令用来退出环境。


### 创建项目

scrapy和一般的Python Package不一样，安装之后会提供命令行工具`scrapy`，并使用这个工具来创建爬虫项目。

我们使用startproject子命令来创建项目，项目名为`demo`。
```bash
scrapy startproject demo
```
scrapy会在当前目录下帮我创建一个如下的目录结构，包括爬虫项目的代码和配置。我们的工作是在这些上面进行修改，来完成自己的目标。
```bash
demo
├── demo
│   ├── __init__.py
│   ├── items.py
│   ├── middlewares.py
│   ├── pipelines.py
│   ├── settings.py
│   └── spiders
│       └── __init__.py
└── scrapy.cfg

2 directories, 7 files
```

从`tree demo`结果可以看成，`scrapy.cfg`是项目的配置文件，`demo`子目录里包含了项目代码，`items.py`文件中定义爬虫爬取的目标的字段信息，`pipelines.py`文件里定义了流水线，适合需要多个步骤的项目，`settings.py`是设置文件，比如设置多个流水线的执行优先级，设置是否遵守robots.txt文件的要求等。`spiders.py`子目录里是爬虫的具体代码实现，现在这里没有文件，后续会添加具体的爬虫脚本。

### 实现爬虫



#### 定义Item

#### 生成爬虫

我们可以使用`genspider`子命令根据模板来生成基础的爬虫脚本，`genspider`子命令有两个参数，分别为爬虫的名字和要爬取数据的网站的url。
```bash
scrapy genspider genshin https://wiki.biligame.com/ys/%E8%A7%92%E8%89%B2%E7%AD%9B%E9%80%89
```
这里我爬取的数据是[BiWiki](https://wiki.biligame.com/)原神版，爬虫名为genshin。这个命令为在`spiders`目录下生成`genshin.py`文件，并载入基础代码。
```bash
demo
├── demo
│   ├── __init__.py
│   ├── items.py
│   ├── middlewares.py
│   ├── pipelines.py
│   ├── settings.py
│   └── spiders
│       ├── __init__.py
│       └── genshin.py
└── scrapy.cfg

2 directories, 8 files
```
`genshin.py`文件中定义了`GenshinSpider`类，其中的`parse`方法就是实现爬虫数据解析的地方，方法的入参`response`是`scrapy`框架请求`start_urls`中的链接返回的响应，我们需要从这个`response`中解析出需要的数据。
```python
import scrapy


class GenshinSpider(scrapy.Spider):
    name = "genshin"
    allowed_domains = ["wiki.biligame.com"]
    start_urls = ["https://wiki.biligame.com/ys/%E8%A7%92%E8%89%B2%E7%AD%9B%E9%80%89"]

    def parse(self, response):
        pass

```
#### 完善逻辑

