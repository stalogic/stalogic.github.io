---
layout:     post
title:      Scrapy爬虫框架简易使用
subtitle:    "\"人生苦短我用Python\""
date:       2024-04-11
author:     Eason
header-img: img/post-bg-swanlake.jpg
catalog: true
tags:
    - Scrapy
    - Python
    - 爬虫
---



## 前言

最近想用二游的文本来微调大模型，看看能玩出什么有意思的东西。首先得爬取游戏的文本信息，Scrapy是Python爬虫框架，通过阅读文档和博客，很轻松掌握的Scrapy的简单使用，完成爬取数据的目标。

---

### 安装&环境配置

scrapy依赖python环境，可以通过conda创建虚拟环境
```bash
conda create -n venv python=3.10 scrapy
```
顺利安装完成的话，会看见下面的提示

```
# To activate this environment, use
#
#     $ conda activate venv
#
# To deactivate an active environment, use
#
#     $ conda deactivate
```
通过`conda activate venv`命令就可以进入虚拟环境，`conda deactivate`命令用来退出环境。


### 创建项目

scrapy和一般的Python Package不一样，安装之后会提供命令行工具`scrapy`，并使用这个工具来创建爬虫项目。

我们使用startproject子命令来创建项目，项目名为`demo`。
```bash
scrapy startproject demo
```
scrapy会在当前目录下帮我创建一个如下的目录结构，包括爬虫项目的代码和配置。我们的工作是在这些上面进行修改，来完成自己的目标。
```bash
demo
├── demo
│   ├── __init__.py
│   ├── items.py
│   ├── middlewares.py
│   ├── pipelines.py
│   ├── settings.py
│   └── spiders
│       └── __init__.py
└── scrapy.cfg

2 directories, 7 files
```

从`tree demo`结果可以看成，`scrapy.cfg`是项目的配置文件，`demo`子目录里包含了项目代码，`items.py`文件中定义爬虫爬取的目标的字段信息，`pipelines.py`文件里定义了流水线，适合需要多个步骤的项目，`settings.py`是设置文件，比如设置多个流水线的执行优先级，设置是否遵守robots.txt文件的要求等。

### 实现爬虫

`spiders.py`子目录里是爬虫的具体代码实现，现在这里没有文件，我们可以使用`genspider`子命令根据模板来生成基础的爬虫脚步。

#### 定义Item

#### 生成爬虫

#### 完善逻辑

